# -*- coding: utf-8 -*-
"""Unmasked.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wwwnJYhUBV01zvieLQpn6EPls7ebvzBi
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import numpy as np
import cv2
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import tensorflow
from tensorflow import keras
from tqdm import tqdm

no_mask = []
with_mask = []

path = "drive/MyDrive/Colab Notebooks/Unmasked/mask_data"

# # reads in all the masked images
# for filename in sorted(os.listdir(path + "/with_mask")):
#   full_path = os.path.join(path + "/with_mask", filename)
#   image = cv2.imread(full_path)
#   resized_image = cv2.resize(image, (64, 64))

#   with_mask.append(resized_image)

# # reads in all the no masked images
# for filename in sorted(os.listdir(path + "/without_mask")):
#   full_path = os.path.join(path + "/without_mask", filename)
#   print(full_path)
#   image = cv2.imread(full_path)
#   resized_image = cv2.resize(image, (64, 64))

#   no_mask.append(resized_image)



for i in range(100, 1000):
  with_image = cv2.imread(path + "/with_mask/with-mask-default-mask-seed0" + str(i) + ".png")
  resized_with = cv2.resize(with_image, (64, 64))
  without_image = cv2.imread(path + "/without_mask/seed0" + str(i) + ".png")
  resized_without = cv2.resize(without_image, (64, 64))

  no_mask.append(resized_with)
  with_mask.append(resized_without)

x_dataset = np.array(no_mask)
x_dataset = x_dataset.astype('float32')
x_dataset = x_dataset / 255.0


y_dataset = np.array(with_mask)
y_dataset = y_dataset.astype('float32')
y_dataset = y_dataset / 255.0

print(x_dataset.shape)
print(y_dataset.shape)

plt.imshow(x_dataset[0])

x_train, x_test, y_train, y_test = train_test_split(x_dataset, y_dataset, test_size = 0.2, shuffle = False)

#create generator

# generator = keras.models.Sequential()
# generator.add(keras.Input(shape=(64, 64, 3)))

# generator.add(keras.layers.Conv2D(64, (5, 5), strides = (2, 2), padding="same"))
# generator.add(keras.layers.BatchNormalization())
# generator.add(keras.layers.LeakyReLU(0.2))

# generator.add(keras.layers.Conv2D(128, (5, 5), strides = (2, 2), padding="same"))
# generator.add(keras.layers.BatchNormalization())
# generator.add(keras.layers.LeakyReLU(0.2))

# generator.add(keras.layers.Conv2D(256, (5, 5), strides = (2, 2), padding="same"))
# generator.add(keras.layers.BatchNormalization())
# generator.add(keras.layers.LeakyReLU(0.2))

# generator.add(keras.layers.Conv2D(512, (5, 5), strides = (2, 2), padding="same"))
# generator.add(keras.layers.BatchNormalization())
# generator.add(keras.layers.LeakyReLU(0.2))

# #Transposed convolutional layers
# generator.add(keras.layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding="same"))
# generator.add(keras.layers.BatchNormalization())
# generator.add(keras.layers.LeakyReLU(0.2))

# generator.add(keras.layers.Conv2DTranspose(128, (5, 5), strides = (2, 2), padding="same"))
# generator.add(keras.layers.BatchNormalization())
# generator.add(keras.layers.LeakyReLU(0.2))

# generator.add(keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding="same"))
# generator.add(keras.layers.BatchNormalization())
# generator.add(keras.layers.LeakyReLU(0.2))

# generator.add(keras.layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding="same", activation="tanh"))

#create discriminator -- note that we will be adding the image to be classified along with its initial image

# discriminator = keras.models.Sequential()
# discriminator.add(keras.Input(shape=(64, 64, 3, 2)))

# discriminator.add(keras.layers.Conv2D(64, (5, 5), strides=(2, 2), paddings = "same"))
# discriminator.add(keras.layers.LeakyReLU(0.2))
# discriminator.add(keras.layers.Dropout(0.3))

# discriminator.add(keras.layers.Conv2D(128, (5, 5), strides=(2, 2), paddings = "same"))
# discriminator.add(keras.layers.LeakyReLU(0.2))
# discriminator.add(keras.layers.Dropout(0.3))

# discriminator.add(keras.layers.Conv2D(256, (5, 5), strides=(2, 2), paddings = "same"))
# discriminator.add(keras.layers.LeakyReLU(0.2))
# discriminator.add(keras.layers.Dropout(0.3))

# discriminator.add(keras.layers.Conv2D(512, (5, 5), strides=(2, 2), paddings = "same"))
# discriminator.add(keras.layers.LeakyReLU(0.2))
# discriminator.add(keras.layers.Dropout(0.3))

# discriminator.add(keras.layers.Flatten())
# discriminator.add(keras.layers.Dense(1, activation="sigmoid"))

# #combine into GAN - show model summary
# gan = keras.Sequential([generator, discriminator])

input = keras.layers.Input(shape=(64, 64, 3), name="mask_input")
conv2D1 = keras.layers.Conv2D(64, (5, 5), strides = (2, 2), padding="same")(input)
batch1 = keras.layers.BatchNormalization()(conv2D1)
leaky1 = keras.layers.LeakyReLU(0.2)(batch1)

conv2D2 = keras.layers.Conv2D(128, (5, 5), strides = (2, 2), padding="same")(leaky1)
batch2 = keras.layers.BatchNormalization()(conv2D2)
leaky2 = keras.layers.LeakyReLU(0.2)(batch2)

conv2D3 = keras.layers.Conv2D(256, (5, 5), strides = (2, 2), padding = "same")(leaky2)
leaky3 = keras.layers.LeakyReLU(0.2)(conv2D3)

convT4 = keras.layers.Conv2DTranspose(128, (5, 5), strides = (2, 2), padding = "same")(leaky3)
batch4 = keras.layers.BatchNormalization()(convT4)
leaky4 = keras.layers.LeakyReLU(0.2)(batch4)

convT5 = keras.layers.Conv2DTranspose(256, (5, 5), strides = (2, 2), padding = "same")(leaky4)
leaky5 = keras.layers.LeakyReLU(0.2)(convT5)

fake_out = keras.layers.Conv2DTranspose(3, (5, 5), strides = (2, 2), padding = "same")(leaky5)

generator = keras.Model(inputs=[input], outputs = [fake_out])

generator.summary()

# input2 = keras.layers.Input(shape=[64, 64, 6], name = "disc_input")
concat = keras.layers.Concatenate()([input, fake_out])
dconv1 = keras.layers.Conv2D(64, (5, 5), strides = (2, 2), padding="same")(concat)
dleaky1 = keras.layers.LeakyReLU(0.2)(dconv1)
ddropout1 = keras.layers.Dropout(0.3)(dleaky1)

dconv2 = keras.layers.Conv2D(128, (5, 5), strides = (2, 2), padding="same")(ddropout1)
dleaky2 = keras.layers.LeakyReLU(0.2)(dconv2)
ddropout2 = keras.layers.Dropout(0.3)(dleaky2)

dconv3 = keras.layers.Conv2D(256, (5, 5), strides = (2, 2), padding="same")(ddropout2)
dleaky3 = keras.layers.LeakyReLU(0.2)(dconv3)
ddropout3 = keras.layers.Dropout(0.3)(dleaky3)

flat = keras.layers.Flatten()(ddropout3)
output = keras.layers.Dense(1, activation = "sigmoid")(flat)

gan = keras.Model(inputs = [input], outputs = [output])


discriminator = keras.Model(inputs = [dconv1], outputs = [output])
discriminator.trainable = False
discriminator.summary()
gan.summary()

keras.utils.plot_model(gan, to_file='model.png', show_shapes = True, show_layer_names = False)

batch_size = 32

epochs = 100

ranIntArr = np.arange(0, x_train.shape[0])
dataset = tensorflow.data.Dataset.from_tensor_slices(ranIntArr)

dataset = dataset.batch(batch_size, drop_remainder = True).prefetch(1)

for epoch in tqdm(range(epochs)):
    print()
    print("Epoch {}/{}".format(epoch + 1, epochs))

    fake_faces = []
    real_faces = []
    gen_train = []
    y1 = tensorflow.constant(([[0.]] * batch_size) + ([[1.]] * batch_size))

    for x in dataset:
      fake_faces.append(np.reshape([generator(x_train[x]), x_train[x]], (64, 64, 6))) #creates fake images and append them
      real_faces.append(np.reshape([y_train[x], x_train[x]]),(64, 64, 6))
      gen_train.append(x_train[x])

    x_train = tensorflow.concat([fake_faces, real_faces], axis=0)
    discriminator.trainable = True
    discriminator.train_on_batch(x_train, y1)

    discriminator.trainable = False

    #Creating dataset to train generator
    y2 = tensorflow.constant([[1.]] * (batch_size))
    gan.train_on_batch(gen_train, y2)

plt.imshow(generator(x_test[0]))